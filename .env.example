# Environment variables for TheMule Atomic HITL Tool

# --- Google Generative AI Configuration ---
# Required if you want to use Google's Generative AI models (e.g., Gemini).
# Get your API key from Google AI Studio: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"

# --- Local LLM Configuration ---
# Required if you want to use a locally hosted LLM (e.g., via Ollama, LM Studio, etc.)
# that exposes an OpenAI-compatible API endpoint.
# This should be the base URL of your local LLM's API.
# Example for Ollama (if OpenAI compatibility is enabled/default): http://localhost:11434/v1
# Example for a generic OpenAI-compatible server: http://localhost:1234/v1
LOCAL_LLM_BASE_URL="http://localhost:11434/v1"

# --- Other Optional Variables ---
# Add any other environment variables your application might need here.
# EXAMPLE_VARIABLE="some_value"

# Note:
# - Copy this file to .env and fill in your actual values.
# - Do NOT commit your .env file to version control if it contains sensitive keys.
#   The .gitignore file should already include .env.
# - The application uses the `python-dotenv` library to load these variables.
# - Refer to `src/themule_atomic_hitl/config.py` for how these are used,
#   particularly within the `llm_config` section for provider details like
#   `api_key_env` and `base_url_env`.
